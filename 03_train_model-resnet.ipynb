{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# set inputs to train based for different CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_file_name = \"resnet_features.pkl\"\n",
    "checkpoint_output_file = 'resnet-model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "history_file_name = \"resnet-model_run_history.pkl\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# you dont need to touch any of the below\n",
    "\n",
    "just run and wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from utils.helpers import Config\n",
    "from utils.dataprep import load_set, load_photo_features\n",
    "from utils.dataprep import load_clean_descriptions, get_tokenizer, max_length_desc\n",
    "from utils.inputprep import create_sequences, data_generator\n",
    "\n",
    "c = Config()\n",
    "\n",
    "\n",
    "feature_file_name = c.ExtractedFeaturesFilePath(feature_file_name)\n",
    "checkpoint_output_file = checkpoint_output_file\n",
    "history_file_name = c.ExtractedFeaturesFilePath(history_file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train ids: 6000, and dev ids: 1000\n",
      "Train photos: 6000, and dev photos: 1000\n"
     ]
    }
   ],
   "source": [
    "# 1. load train and dev images features \n",
    "train = load_set(c.FlickrTextFilePath(\"Flickr_8k.trainImages.txt\"))\n",
    "dev = load_set(c.FlickrTextFilePath(\"Flickr_8k.devImages.txt\"))\n",
    "\n",
    "# use VGG trained features \n",
    "train_features = load_photo_features(feature_file_name, train)\n",
    "dev_features = load_photo_features(feature_file_name, dev)\n",
    "\n",
    "print(\"Train ids: %i, and dev ids: %i\" % (len(train), len(dev)))\n",
    "print(\"Train photos: %i, and dev photos: %i\" % (len(train_features), len(dev_features)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features[\"3009047603_28612247d2\"].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train descriptions: 6000, and dev descriptions: 1000\n"
     ]
    }
   ],
   "source": [
    "# 2. load clean descriptions for data sets. and load vocabulary \n",
    "\n",
    "train_descriptions = load_clean_descriptions(c.ExtractedFeaturesFilePath('descriptions.txt'), train)\n",
    "dev_descriptions = load_clean_descriptions(c.ExtractedFeaturesFilePath('descriptions.txt'), dev)\n",
    "\n",
    "print(\"Train descriptions: %i, and dev descriptions: %i\" % (len(train_descriptions), len(dev_descriptions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokensizer vocalulary size: 7579, Description max length: 34 \n"
     ]
    }
   ],
   "source": [
    "# 3. tokensize train and dev sets \n",
    "\n",
    "# prepare tokensizer\n",
    "tokenizer = get_tokenizer(c.TokenizerFilePath) \n",
    "max_length = max_length_desc(train_descriptions)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "print( \"Tokensizer vocalulary size: %i, Description max length: %i \" % (vocab_size, max_length))\n",
    "# TODO: here we should save the tokenizer for later use, it will be needed when traslating yhat vector to a description \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # 4. define and fit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical, plot_model\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, LSTM, Embedding, Dropout\n",
    "from keras.layers.merge import add\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# define the captioning model\n",
    "def define_model(vocab_size, max_length, input_dim = 4096):\n",
    "\t# feature extractor model\n",
    "\tinputs1 = Input(shape=(input_dim,))\n",
    "\tfe1 = Dropout(0.5)(inputs1)\n",
    "\tfe2 = Dense(256, activation='relu')(fe1)\n",
    "\t# sequence model\n",
    "\tinputs2 = Input(shape=(max_length,))\n",
    "\tse1 = Embedding(vocab_size, 256, mask_zero=True)(inputs2)\n",
    "\tse2 = Dropout(0.5)(se1)\n",
    "\tse3 = LSTM(256)(se2)\n",
    "\t# decoder model\n",
    "\tdecoder1 = add([fe2, se3])\n",
    "\tdecoder2 = Dense(256, activation='relu')(decoder1)\n",
    "\toutputs = Dense(vocab_size, activation='softmax')(decoder2)\n",
    "\t# tie it together [image, seq] [word]\n",
    "\tmodel = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "\t# compile model\n",
    "\tmodel.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\t# summarize model\n",
    "\tmodel.summary()\n",
    "\t# plot_model(model, to_file='model.png', show_shapes=True)\n",
    "\treturn model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/control_flow_ops.py:423: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 34)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_1 (InputLayer)            (None, 2048)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 34, 256)      1940224     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 34, 256)      0           embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 256)          524544      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          525312      dropout_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 256)          0           dense_1[0][0]                    \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 256)          65792       add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 7579)         1947803     dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 5,003,675\n",
      "Trainable params: 5,003,675\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_dim = train_features[\"3009047603_28612247d2\"].shape[1]\n",
    "model = define_model(vocab_size, max_length, input_dim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_generator = data_generator(train_descriptions, train_features, tokenizer, max_length)\n",
    "dev_data_generator = data_generator(dev_descriptions, dev_features, tokenizer, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define checkpoint callback\n",
    "filepath = checkpoint_output_file # 'model-ep{epoch:03d}-loss{loss:.3f}-val_loss{val_loss:.3f}.h5'\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/20\n",
      " - 411s - loss: 4.5462 - val_loss: 4.0087\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 4.00865, saving model to resnet-model-ep001-loss4.565-val_loss4.009.h5\n",
      "Epoch 2/20\n",
      " - 410s - loss: 3.7590 - val_loss: 3.8122\n",
      "\n",
      "Epoch 00002: val_loss improved from 4.00865 to 3.81217, saving model to resnet-model-ep002-loss3.779-val_loss3.812.h5\n",
      "Epoch 3/20\n",
      " - 411s - loss: 3.4925 - val_loss: 3.7923\n",
      "\n",
      "Epoch 00003: val_loss improved from 3.81217 to 3.79227, saving model to resnet-model-ep003-loss3.513-val_loss3.792.h5\n",
      "Epoch 4/20\n",
      " - 409s - loss: 3.3356 - val_loss: 3.7993\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 3.79227\n",
      "Epoch 5/20\n",
      " - 405s - loss: 3.2339 - val_loss: 3.7802\n",
      "\n",
      "Epoch 00005: val_loss improved from 3.79227 to 3.78024, saving model to resnet-model-ep005-loss3.256-val_loss3.780.h5\n",
      "Epoch 6/20\n",
      " - 405s - loss: 3.1592 - val_loss: 3.8450\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 3.78024\n",
      "Epoch 7/20\n",
      " - 406s - loss: 3.1026 - val_loss: 3.8876\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 3.78024\n",
      "Epoch 8/20\n",
      " - 405s - loss: 3.0564 - val_loss: 3.8678\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 3.78024\n",
      "Epoch 9/20\n",
      " - 404s - loss: 3.0219 - val_loss: 3.8786\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 3.78024\n",
      "Epoch 10/20\n",
      " - 405s - loss: 2.9969 - val_loss: 3.9269\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 3.78024\n",
      "Epoch 11/20\n",
      " - 404s - loss: 2.9729 - val_loss: 3.9211\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 3.78024\n",
      "Epoch 12/20\n",
      " - 404s - loss: 2.9513 - val_loss: 3.9535\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 3.78024\n",
      "Epoch 13/20\n",
      " - 404s - loss: 2.9388 - val_loss: 3.9420\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 3.78024\n",
      "Epoch 14/20\n",
      " - 405s - loss: 2.9243 - val_loss: 3.9788\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 3.78024\n",
      "Epoch 15/20\n",
      " - 405s - loss: 2.9140 - val_loss: 3.9826\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 3.78024\n",
      "Epoch 16/20\n",
      " - 404s - loss: 2.9037 - val_loss: 3.9875\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 3.78024\n",
      "Epoch 17/20\n",
      " - 405s - loss: 2.9035 - val_loss: 4.0017\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 3.78024\n",
      "Epoch 18/20\n",
      " - 404s - loss: 2.8927 - val_loss: 4.0183\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 3.78024\n",
      "Epoch 19/20\n",
      " - 404s - loss: 2.8905 - val_loss: 4.0082\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 3.78024\n",
      "Epoch 20/20\n",
      " - 404s - loss: 2.8834 - val_loss: 4.0270\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 3.78024\n"
     ]
    }
   ],
   "source": [
    " history = model.fit_generator(\n",
    " \ttrain_data_generator,\n",
    " \tepochs=20,\n",
    " \tsteps_per_epoch=len(train_descriptions),\n",
    " \tverbose=2, # 1: progress, 2: one line per epoch\n",
    " \tvalidation_data= dev_data_generator,\n",
    " \tvalidation_steps=len(dev_descriptions),\n",
    " \tcallbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save history\n",
    "import pickle\n",
    "\n",
    "with open(history_file_name, \"wb\") as pcklfile:\n",
    "    pickle.dump(history, pcklfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/home/mutaz/notebooks/dl_at3'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
