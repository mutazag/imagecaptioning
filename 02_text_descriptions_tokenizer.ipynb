{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Prepare Text Descriptions\n",
    " Data set includes text desprtions for all images in the Flickr8k_text folder\n",
    " - Flickr8k.token.txt: reference descriptions for images, 5 descriptions for each image\n",
    "   1000268201_693b08cb0e.jpg#0\tA child in a pink dress is climbing up a set of stairs in an entry way .\n",
    "   1000268201_693b08cb0e.jpg#1\tA girl going into a wooden building .\n",
    "   1000268201_693b08cb0e.jpg#2\tA little girl climbing into a wooden playhouse .\n",
    "   1000268201_693b08cb0e.jpg#3\tA little girl climbing the stairs to her playhouse .\n",
    "   1000268201_693b08cb0e.jpg#4\tA little girl in a pink dress going into a wooden cabin .\n",
    " list of images for data split:\n",
    " - train: Flickr_8k.trainImages.txt\n",
    " - dev: Flickr_8k.devImages.txt\n",
    " - test:Flickr_8k.testImages.txt\n",
    " also prepare a tokenizer and save it to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# import libraries \n",
    "import numpy as np \n",
    "from utils.helpers import Config\n",
    "from utils.dataprep import load_doc, load_descriptions, clean_descriptions, save_descriptions\n",
    "from utils.dataprep import to_vocabulary, save_vocabulary, load_vocabulary\n",
    "from utils.dataprep import load_set,load_clean_descriptions, create_tokenizer, get_tokenizer\n",
    "\n",
    "# setting seed\n",
    "np.random.seed(42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = Config() \n",
    "\n",
    "filename = c.FlickrTextFilePath(\"Flickr8k.token.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prepare descriptions from dataset\n",
    "\n",
    "* load flickr8k tokens file\n",
    "* create descriptions from the tokens file\n",
    "* save the clean descriptions for later reuse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded descriptions: 8092 \n"
     ]
    }
   ],
   "source": [
    "# load descriptions\n",
    "doc = load_doc(filename)\n",
    "# parse descriptions\n",
    "descriptions = load_descriptions(doc)\n",
    "print('Loaded descriptions: %d ' % len(descriptions))\n",
    "# clean descriptions\n",
    "clean_descriptions(descriptions)\n",
    "# save to file to the same folder as image extracted features since this \n",
    "# is a processed file to be used in later stages\n",
    "save_descriptions(descriptions, c.ExtractedFeaturesFilePath('descriptions.txt')) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "create a vocabulary object based on clean descriptions from the flickr8k tokens data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 8763\n",
      "Vocabulary created and saved to data/Extracted_Features/vocabulary.pkl\n"
     ]
    }
   ],
   "source": [
    "# summarize vocabulary\n",
    "vocabulary = to_vocabulary(descriptions)\n",
    "print('Vocabulary Size: %d' % len(vocabulary))\n",
    "save_vocabulary(vocabulary, c.ExtractedFeaturesFilePath(\"vocabulary.pkl\"))\n",
    "print(\"Vocabulary created and saved to %s\" %(c.ExtractedFeaturesFilePath(\"vocabulary.pkl\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tokenizer\n",
    "\n",
    "The following cell uses the utility function `create_tokenizer` to create and save the tokenizer object so we dont have to recreate it later when it is needed. the tokenizer can be retrieved using the `get_tokenizer(c.ToneknizerFilePath)` function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer text_to_seq output sample: [[4, 24, 6216, 68, 45, 4, 8]]\n",
      "Tokenizer created and saved to data/Extracted_Features/tokenizer.pkl\n"
     ]
    }
   ],
   "source": [
    "train = load_set(c.FlickrTextFilePath(\"Flickr_8k.trainImages.txt\"))\n",
    "train_descriptions = load_clean_descriptions(c.ExtractedFeaturesFilePath('descriptions.txt'), train)\n",
    "tokenizer = create_tokenizer(train_descriptions, c.TokenizerFilePath) \n",
    "\n",
    "#sample use of the tokenizer: \n",
    "\n",
    "seq = tokenizer.texts_to_sequences([\"The quick brown fox jumps over the lazy dog\"])\n",
    "print(\"Tokenizer text_to_seq output sample: %s\" %(seq))\n",
    "print(\"Tokenizer created and saved to %s\" % (c.TokenizerFilePath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example for loading and using a preperared tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4, 24, 6216, 68, 45, 4, 8]]\n",
      "7579\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tt2 = get_tokenizer(c.TokenizerFilePath)\n",
    "print(tt2.texts_to_sequences([\"The quick brown fox jumps over the lazy dog\"])) \n",
    "print(len(tokenizer.word_index) + 1)\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3.5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
